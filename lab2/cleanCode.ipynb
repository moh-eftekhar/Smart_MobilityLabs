{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo as pm\n",
    "import pprint\n",
    "from enum import Enum\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "#---------------------------------------------------------- Connect to MongoDB\n",
    "client = pm.MongoClient('bigdatadb.polito.it',                     \n",
    "                        ssl=True,                     \n",
    "                        authSource = 'carsharing',                     \n",
    "                        username = 'ictts',                     \n",
    "                        password ='Ict4SM22!',                     \n",
    "                        tlsAllowInvalidCertificates=True) \n",
    "db = client['carsharing'] \n",
    "#Choose the DB to use \n",
    "permenant_booking = db['PermanentBookings']\n",
    "permenant_parking = db['PermanentParkings']\n",
    "enjoy_permenant_booking = db['enjoy_PermanentBookings']\n",
    "enjoy_permenant_parking = db['enjoy_PermanentParkings']\n",
    "#ENUM of cities\n",
    "class CITY_ENUM(Enum):\n",
    "    TO = 'Torino'\n",
    "    SEA = 'Seattle'\n",
    "    STU = 'Stuttgart'\n",
    "class CITY_TIMEZONES(Enum):\n",
    "    TO = 'Europe/Rome'\n",
    "    SEA = 'America/Los_Angeles'\n",
    "    STU = 'Europe/Berlin'\n",
    "\n",
    "# def get_start_end_unix_zone(timezone):\n",
    "#     # start_timestamp = datetime(2018, 1, 1,0,0,0,0, pytz.timezone(timezone)).timestamp()\n",
    "#     # end_timestamp  = datetime(2018, 1, 31,23,59,59,0, pytz.timezone(timezone)).timestamp()\n",
    "#     return start_timestamp,end_timestamp\n",
    "start_unix_time = datetime.strptime(\"01/01/2018\", \"%d/%m/%Y\").timestamp()\n",
    "end_unix_time = datetime.strptime(\"31/01/2018\", \"%d/%m/%Y\").timestamp()\n",
    "\n",
    "#pipeline for getting the data for the rentals with the filteration of the data\n",
    "#too short and too long rentals are filtered out\n",
    "#considered if car is moved\n",
    "def filter_pipeline(city,start_unix_time,end_unix_time):\n",
    "    return [\n",
    "    {\n",
    "        '$match': {\n",
    "            'city': city,\n",
    "            'init_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lt': end_unix_time\n",
    "            },\n",
    "            'final_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lt': end_unix_time\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'duration': {\n",
    "                '$divide': [\n",
    "                    { '$subtract': ['$final_time', '$init_time'] },\n",
    "                    60  # Divide by 60 to convert seconds to minutes\n",
    "                ]\n",
    "            },\n",
    "            'day': {'$dayOfMonth': '$init_date'},\n",
    "            'hour': {'$hour': '$init_date'},\n",
    "            'date': {\n",
    "                '$dateToString': {\n",
    "                    'format': '%Y-%m-%d',\n",
    "                    'date': '$init_date'\n",
    "                }\n",
    "            },\n",
    "            'moved': {\n",
    "                '$ne':[\n",
    "                    {\"$arrayElemAt\": [ \"$origin_destination.coordinates\", 0]},\n",
    "                    {\"$arrayElemAt\": [ \"$origin_destination.coordinates\", 1]}\n",
    "                 ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$match': {\n",
    "            'moved': True,\n",
    "            'duration':{'$gt':5, '$lt':180},\n",
    "                \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group':{\n",
    "            '_id': {'day': '$day', 'hour': '$hour', 'date': '$date'},\n",
    "            'total_count': {'$sum': 1},\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1,\n",
    "        }\n",
    "    },\n",
    "]\n",
    "#---------------------------------------------------------- Get the data from MongoDB\n",
    "TO_Data = list(enjoy_permenant_booking.aggregate(filter_pipeline(CITY_ENUM.TO.value,\n",
    "          start_unix_time,end_unix_time)))\n",
    "SEA_Data = list(permenant_booking.aggregate(filter_pipeline(CITY_ENUM.SEA.value,\n",
    "          start_unix_time,end_unix_time)))\n",
    "STU_Data = list(permenant_booking.aggregate(filter_pipeline(CITY_ENUM.STU.value,\n",
    "          start_unix_time,end_unix_time)))\n",
    "cities_data_array = [(CITY_ENUM.TO.value,TO_Data),(CITY_ENUM.SEA.value,SEA_Data),(CITY_ENUM.STU.value,STU_Data)]\n",
    "#---------------------------------------------------------- check for missing data\n",
    "print(\"TO_Data\",len(TO_Data))\n",
    "print(\"SEA_Data\",len(SEA_Data))\n",
    "print(\"STU_Data\",len(STU_Data))\n",
    "#---------------------------------------------------------- Dropping _id and Flattening the data\n",
    "def dfModifier(city_list):\n",
    "  df = pd.DataFrame(city_list, columns =['_id', 'total_count'])\n",
    "  df['date'] = df['_id'].apply(lambda x: x['date'])\n",
    "  df['day'] = df['_id'].apply(lambda x: x['day'])\n",
    "  df['hour'] = df['_id'].apply(lambda x: x['hour'])\n",
    "  df['myIndex'] = (df['day']-1)*24 + (df['hour']+1)\n",
    "  df.drop(['_id'], axis=1, inplace=True)\n",
    "  return df\n",
    "#day | hour\n",
    "#1   | 0 -> day*24 + hour => 1*24 + 0 = 24\n",
    "#1   | 1 -> day*24 + hour => 1*24 + 1 = 25\n",
    "#1   | 2 -> day*24 + hour => 1*24 + 2 = 26\n",
    "#day | hour\n",
    "#0   | 1 -> day*24 + hour => 0*24 + 1 = 1\n",
    "#0   | 2 -> day*24 + hour => 0*24 + 2 = 2\n",
    "#0   | 3 -> day*24 + hour => 0*24 + 3 = 3\n",
    "TO_df = dfModifier(TO_Data)\n",
    "SEA_df = dfModifier(SEA_Data)\n",
    "STU_df = dfModifier(STU_Data)\n",
    "cities_df_array = [(CITY_ENUM.TO.value,TO_df),(CITY_ENUM.SEA.value,SEA_df),(CITY_ENUM.STU.value,STU_df)]\n",
    "#---------------------------------------------------------- Calculating hourly mean\n",
    "# calculating the avg for each hour of the day\n",
    "TO_hourly_avg = TO_df.groupby('hour')['total_count'].mean().round().reset_index().astype(int)['total_count'].tolist()\n",
    "SEA_hourly_avg = SEA_df.groupby('hour')['total_count'].mean().round().reset_index().astype(int)['total_count'].tolist()\n",
    "STU_hourly_avg = STU_df.groupby('hour')['total_count'].mean().round().reset_index().astype(int)['total_count'].tolist()\n",
    "#---------------------------------------------------------- Filling the missing data with the mean\n",
    "def fillMissingValues(df:pd.DataFrame, avg_df):\n",
    "  missingValues=set(np.arange(1,31*24+1)).difference(set(df['myIndex']))\n",
    "  # dfMean = round(np.mean(df['total_count']))\n",
    "  print(\"Missing values are:\", len(missingValues), missingValues)\n",
    "  df2 = df\n",
    "  for value in missingValues:\n",
    "    dayOfValue = int((value-1)/24)+1\n",
    "    hourOfValue = (value-1)%24\n",
    "    new_row = pd.DataFrame({'total_count':avg_df[hourOfValue],'date':f'2018-01-{dayOfValue:02d}',\n",
    "                            'day':dayOfValue,'hour':hourOfValue,'myIndex':value}, index =[0])\n",
    "    df2 = pd.concat([new_row,df2.loc[:]]).reset_index(drop = True)\n",
    "  df2.sort_values(by=['myIndex'], inplace=True)\n",
    "  return df2\n",
    "\n",
    "To_FilledValues = fillMissingValues(TO_df, TO_hourly_avg)\n",
    "SEA_FilledValues = fillMissingValues(SEA_df,SEA_hourly_avg)\n",
    "STU_FilledValues = fillMissingValues(STU_df,SEA_hourly_avg)\n",
    "#---------------------------------------------------------- Plotting the data with Rolling mean and checking for stationarity\n",
    "def plotter(plotTitle, df:pd.DataFrame):\n",
    "    mean = df['total_count'].rolling(window=24*7).mean()\n",
    "    std = df['total_count'].rolling(window=24*7).std()\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df['myIndex'], mean, label='Rolling Mean', color='red')\n",
    "    plt.plot(df['myIndex'], std, label='Rolling Std', color='green')\n",
    "    plt.plot()\n",
    "    plt.plot(df['myIndex'], df['total_count'], label='Rental', color='blue')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Total Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Total Counts in Dates and Hours in - {plotTitle}')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{plotTitle}-Roolings-mean-std')\n",
    "    plt.clf()\n",
    "plotter('Torino',To_FilledValues)\n",
    "plotter('Seattle',SEA_FilledValues)\n",
    "plotter('Stuttgart',STU_FilledValues)\n",
    "#---------------------------------------------------------- making a clean data\n",
    "cleanFilledCities = [(CITY_ENUM.TO.value,To_FilledValues),(CITY_ENUM.SEA.value,SEA_FilledValues),(CITY_ENUM.STU.value,STU_FilledValues)]\n",
    "#---------------------------------------------------------- Computing ACF and PACF and Plotting them\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "\n",
    "# Use ACF to find q.\n",
    "# Use PACF to find p.\n",
    "\n",
    "def ACF_PACF(city_data):\n",
    "  # plot acf\n",
    "  plt.figure(figsize=(6,4))\n",
    "  plot_acf(city_data[1][\"total_count\"], lags=48)\n",
    "  plt.title(f'Autocorrelation Function 48 Hours - {city_data[0]}')\n",
    "  plt.xlabel('Lags')\n",
    "  plt.grid(True)\n",
    "  # plt.show()\n",
    "  plt.savefig(f'{city_data[0]}-ACF')\n",
    "\n",
    "  # plot pacf\n",
    "  plt.figure(figsize=(6,4))\n",
    "  plot_pacf(city_data[1][\"total_count\"], lags=48)\n",
    "  plt.title(f'Partial Autocorrelation Function 48 Hours - {city_data[0]}')\n",
    "  plt.xlabel('Lags')\n",
    "  plt.grid(True)\n",
    "  # plt.show()\n",
    "  plt.savefig(f'{city_data[0]}-PACF')\n",
    "  \n",
    "for city_data in cities_df_array:\n",
    "  ACF_PACF(city_data)\n",
    "\n",
    "#---------------------------------------------------------- ARIMA model and prediction\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "q = 4\n",
    "p = 2\n",
    "d = 0\n",
    "train_size = 24 * 7 * 2 # 24 * 7 * 3 # 3 weeks -> we will change this to 14 days\n",
    "test_size = 24 * 3 # 10 days -> this takes too long to run so we will use 72 hours\n",
    "myModel = None\n",
    "def Predictor(cleanCity):\n",
    "  originalData = list(cleanCity[1]['total_count'][:train_size])#.tolist()\n",
    "  y_hat = [None for _ in range(train_size)] # should it be a list or pandas array?\n",
    "  for record in range(train_size,train_size+test_size):\n",
    "    model = ARIMA(originalData, order=(p,d,q))\n",
    "    model_fit = model.fit()\n",
    "    prediction = int(model_fit.forecast()[0])\n",
    "    y_hat.append(prediction)\n",
    "    originalData.append(cleanCity[1]['total_count'][record])\n",
    "    originalData = originalData[1:]\n",
    "    myModel = model_fit\n",
    "\n",
    "  plt.figure(figsize=(15,5))\n",
    "  plt.title(\"Predicted values vs Real values\")\n",
    "  plt.plot(list(cleanCity[1]['total_count'][train_size:train_size+test_size]), color='blue', label=\"Real values\")\n",
    "  plt.plot(list(y_hat[train_size: train_size+test_size]), color='red', label=\"Predicted values\")\n",
    "  plt.legend()\n",
    "  plt.xlabel(\"Lags\")\n",
    "  plt.ylabel(\"Rentals\")\n",
    "  plt.grid(True)\n",
    "  plt.savefig(f'2 day prediction {cleanCity[0]}')\n",
    "  plt.clf()\n",
    "  # plot residual errors\n",
    "  residuals = pd.DataFrame(myModel.resid)\n",
    "  residuals.plot()\n",
    "  plt.title(f'Residuals - {cleanCity[0]}')\n",
    "  plt.xlabel(\"Residual Error\")\n",
    "  plt.ylabel(\"Residuals\")\n",
    "  plt.grid(True)\n",
    "  plt.savefig(f'2 day Residuals {cleanCity[0]}')\n",
    "  plt.clf()\n",
    "  #plot the gaussian density of the residuals\n",
    "  residuals.plot(kind='kde')\n",
    "  plt.title(f'Density of Residuals - {cleanCity[0]}')\n",
    "  plt.xlabel(\"Residual Error\")\n",
    "  plt.ylabel(\"Density\")\n",
    "  plt.grid(True)\n",
    "  plt.savefig(f'2 day Density of Residuals {cleanCity[0]}')\n",
    "  plt.clf()\n",
    "  return y_hat, model_fit\n",
    "#---------------------------------------------------------- Prediction for 3 days\n",
    "#create an array to store the results to be used for the comparison and metrics\n",
    "comparisonArray = []\n",
    "for city_data in cleanFilledCities:\n",
    "  print(city_data[0])\n",
    "  y_hat, model_fit = Predictor(city_data)\n",
    "  y_hat = y_hat[train_size:train_size+test_size]\n",
    "  comparisonArray.append((city_data[0],city_data[1]['total_count'][train_size:train_size+test_size], y_hat, model_fit))\n",
    "#---------------------------------------------------------- Metrics\n",
    "from sklearn.metrics import mean_squared_error,r2_score, mean_absolute_percentage_error\n",
    "for item in comparisonArray:\n",
    "  mse = mean_squared_error(item[1], item[2])\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = r2_score(item[1], item[2])\n",
    "  mape = mean_absolute_percentage_error(item[1], item[2])\n",
    "  print(f'{item[0]} -> MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2: {r2:.2f}, MAPE: {mape:.2f}')\n",
    "#---------------------------------------------------------- Runninf model for different P and Q values\n",
    "p = [1,2,3,4,5,6]\n",
    "q = [1,2,3,4]\n",
    "d = 0\n",
    "finalValues = []\n",
    "\n",
    "for cleanCity in cleanFilledCities:\n",
    "  for i in p:\n",
    "    for j in q:\n",
    "      worked = False\n",
    "      originalData = list(cleanCity[1]['total_count'][:train_size])#.tolist()\n",
    "      y_hat = [None for _ in range(train_size)] # should it be a list or pandas array?\n",
    "      for record in range(train_size,train_size+test_size):\n",
    "        try:\n",
    "          model = ARIMA(originalData, order=(i,d,j))\n",
    "          model_fit = model.fit()\n",
    "          prediction = int(model_fit.forecast()[0])\n",
    "          # print(f'Prediction for {cleanCity[0]} at {record} is {prediction}')\n",
    "          y_hat.append(prediction) #shoudl it be int(prediction) or prediction as a float\n",
    "          originalData.append(cleanCity[1]['total_count'][record])\n",
    "          originalData = originalData[1:]\n",
    "          worked = True\n",
    "        except:\n",
    "          print(\"error\")\n",
    "          worked = False\n",
    "          continue\n",
    "      if worked:\n",
    "        actual_values = cleanCity[1]['total_count'][train_size:train_size+test_size]\n",
    "        prediction_values = y_hat[train_size:train_size+test_size]\n",
    "        mse = mean_squared_error(actual_values, prediction_values)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(actual_values, prediction_values)\n",
    "        mape = mean_absolute_percentage_error(actual_values, prediction_values)\n",
    "        finalValues.append((cleanCity[0],i,j,mse,rmse,r2,mape))\n",
    "      elif not worked:\n",
    "        finalValues.append((cleanCity[0],i,j,0,0,0,0))\n",
    "#---------------------------------------------------------- Plotting a heatmap for the results\n",
    "#get the list and  change it to a 2d array to fit the heatmap\n",
    "from itertools import groupby\n",
    "import seaborn as sb\n",
    "\n",
    "# print(finalValues)\n",
    "dont_touch_this = finalValues\n",
    "touchthis = finalValues\n",
    "touchThat = pd.DataFrame(touchthis, columns=['city','p','q','mse','rmse','r2','mape'])\n",
    "#group by city\n",
    "touchThat = touchThat.groupby('city')\n",
    "for name, group in touchThat:\n",
    "    mapeList = group['mape'].tolist()\n",
    "    mapPD = pd.DataFrame(mapeList)\n",
    "    MAPE2d = mapPD.values.reshape(6,4)\n",
    "    print(MAPE2d)\n",
    "    sb.heatmap(MAPE2d, annot=True, cmap=\"YlGnBu\", fmt=\".2f\", linewidths=.5,\n",
    "            xticklabels=[1,2,3,4], yticklabels=[1,2,3,4,5,6])\n",
    "    plt.title(f'MAPE - {name}')\n",
    "    plt.xlabel(\"q\")\n",
    "    plt.ylabel(\"p\")\n",
    "    # plt.show()\n",
    "    plt.savefig(f'MAPE - {name}')\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
