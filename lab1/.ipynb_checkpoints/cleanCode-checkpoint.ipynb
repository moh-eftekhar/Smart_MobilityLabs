{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo as pm \n",
    "import pprint\n",
    "#import MongoClient only \n",
    "client = pm.MongoClient('bigdatadb.polito.it',                     \n",
    "                        ssl=True,                     \n",
    "                        authSource = 'carsharing',                     \n",
    "                        username = 'ictts',                     \n",
    "                        password ='Ict4SM22!',                     \n",
    "                        tlsAllowInvalidCertificates=True) \n",
    "db = client['carsharing'] \n",
    "#Choose the DB to use \n",
    "active_booking = db['ActiveBookings']\n",
    "active_parking = db['ActiveParkings']\n",
    "permenant_booking = db['PermanentBookings']\n",
    "permenant_parking = db['PermanentParkings']\n",
    "\n",
    "enjoy_active_booking = db['enjoy_ActiveBookings']\n",
    "enjoy_active_parking = db['enjoy_ActiveParkings']\n",
    "enjoy_permenant_booking = db['enjoy_PermanentBookings']\n",
    "enjoy_permenant_parking = db['enjoy_PermanentParkings']\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#How many documnets are present in each collection?\n",
    "print(\"active_booking: \", active_booking.count_documents({}))\n",
    "print(\"active_parking: \", active_parking.count_documents({}))\n",
    "print(\"permenant_booking: \", permenant_booking.count_documents({}))\n",
    "print(\"permenant_parking: \", permenant_parking.count_documents({}))\n",
    "print(\"enjoy_active_booking: \", enjoy_active_booking.count_documents({}))\n",
    "print(\"enjoy_active_parking: \", enjoy_active_parking.count_documents({}))\n",
    "print(\"enjoy_permenant_booking: \", enjoy_permenant_booking.count_documents({}))\n",
    "print(\"enjoy_permenant_parking: \", enjoy_permenant_parking.count_documents({}))\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#distinct cities that are served any the system\n",
    "print( len(active_booking.find().distinct(\"city\")), ' --> ',active_booking.find().distinct(\"city\"))\n",
    "print( len(permenant_booking.find().distinct(\"city\")), ' --> ',permenant_booking.find().distinct(\"city\"))\n",
    "print( len(enjoy_active_booking.find().distinct(\"city\")), ' --> ',enjoy_active_booking.find().distinct(\"city\"))\n",
    "print( len(enjoy_permenant_booking.find().distinct(\"city\")), ' --> ',enjoy_permenant_booking.find().distinct(\"city\"))\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "from datetime import datetime\n",
    "collections = [permenant_booking,enjoy_permenant_booking]\n",
    "for collection in collections:\n",
    "    print('collection: ',collection.name)\n",
    "    print('start: ',datetime.fromtimestamp(list(collection.find().sort([(\"init_time\",1)]).limit(1))[0]['init_time']).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    print('end: ',datetime.fromtimestamp(list(collection.find().sort([(\"final_time\",-1)]).limit(1))[0]['final_time']).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#select number of unique cars in the city of Seattle fleet size\n",
    "#we checked for 1 or 2 weeks to see fleet size is less\n",
    "print('Torino-enjoy : ',len(enjoy_permenant_parking.find({'city':'Torino'}).distinct('plate')), len(enjoy_permenant_booking.find({'city':'Torino'}).distinct('plate') ))\n",
    "print('Seattle : ',len(permenant_parking.find({'city':'Seattle'}).distinct('plate')), len(permenant_booking.find({'city':'Seattle'}).distinct('plate')))\n",
    "print('Stuttgart : ',len(permenant_parking.find({'city':'Stuttgart'}).distinct('plate')), len(permenant_booking.find({'city':'Stuttgart'}).distinct('plate')))\n",
    "start_date = datetime.datetime.strptime(\"15/12/2016\", \"%d/%m/%Y\").timestamp()\n",
    "end_date = datetime.datetime.strptime(\"22/12/2016\", \"%d/%m/%Y\").timestamp()\n",
    "start_date2= datetime.datetime.strptime(\"01/11/2017\", \"%d/%m/%Y\").timestamp()\n",
    "end_date2 = datetime.datetime.strptime(\"01/12/2017\", \"%d/%m/%Y\").timestamp()\n",
    "print(len(permenant_parking.find({'city':'Seattle','init_time':{'$gte':start_date,'$lte':end_date}}).distinct('plate')))\n",
    "print(len(permenant_parking.find({'city':'Seattle','init_time':{'$gte':start_date2,'$lte':end_date2}}).distinct('plate')))\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#alternative methods\n",
    "len(list(permenant_booking.find({'city': 'Seattle', 'public_transport.duration': {'$ne': -1}})))\n",
    "len(list(permenant_booking.find({'city': 'Seattle', 'walking.duration': {'$ne': -1}})))\n",
    "len(list(permenant_booking.find({'city': 'Seattle', 'driving.duration': {'$ne': -1}})))\n",
    "#walking is not -1 or public_transport is not -1 or driving is not -1\n",
    "len(list(enjoy_permenant_booking.find({'city': 'Torino', '$or':[{'public_transport.duration': {'$ne': -1}},{'walking.duration': {'$ne': -1}},{'driving.duration': {'$ne': -1}}]})))\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#$tep2 Analysis of the data\n",
    "#2.1\n",
    "start_unix_time = datetime(2017, 11, 1, 0, 0, 0).replace(tzinfo=timezone.utc).timestamp()\n",
    "end_unix_time = datetime(2018, 1, 31, 23, 59, 59).replace(tzinfo=timezone.utc).timestamp()\n",
    "def piper(city,start_unix_time,end_unix_time):\n",
    "    return [\n",
    "    {\n",
    "        '$match': {\n",
    "            'city': city,\n",
    "            'init_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            },\n",
    "            'final_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'duration': {\n",
    "                '$divide': [\n",
    "                    { '$subtract': ['$final_time', '$init_time'] },\n",
    "                    60  # Divide by 60 to convert seconds to minutes\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': { #since the sorting is done in the pipeline, if the result is more than ram capacity then we will get an error. to fix this we can use external sorting with numpy\n",
    "            'duration': 1  # Sorting by duration in ascending order\n",
    "        }\n",
    "    }\n",
    "    ]\n",
    "\n",
    "def normalizer(input_data):\n",
    "    durations = [el['duration'] for el in input_data] #in minutes\n",
    "    cumulated_data = np.zeros(len(durations))\n",
    "    for i in range (len(durations)):\n",
    "        cumulated_data[i] = (i+1)/len(cumulated_data)\n",
    "    return durations, cumulated_data\n",
    "\n",
    "def plotter(booking_durations, booking_cumulated_data, parking_durations, parking_cumulated_data,city, collectionNam):\n",
    "    plt.figure()\n",
    "    plt.semilogx(booking_durations,booking_cumulated_data,label='Permenant_Bookings',color='orange')\n",
    "    plt.semilogx(parking_durations,parking_cumulated_data,label='Permenant_Parkings')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel('Duration [min]')\n",
    "    plt.title('Cdf of bookings and parkings in {}, {}, November 2017 - January 2018'.format(city, collectionNam))\n",
    "    plt.show()\n",
    "\n",
    "City = 'Torino'\n",
    "Nov_Jan_Bookings = enjoy_permenant_booking.aggregate(piper(City,start_unix_time,end_unix_time))\n",
    "Nov_Jan_Parkings = enjoy_permenant_parking.aggregate(piper(City,start_unix_time,end_unix_time))\n",
    "\n",
    "booking_durations, booking_cumulated_data = normalizer(Nov_Jan_Bookings)\n",
    "parking_durations, parking_cumulated_data = normalizer(Nov_Jan_Parkings)\n",
    "plotter(booking_durations, booking_cumulated_data, parking_durations, parking_cumulated_data,City, 'Enjoy')\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#2.1.c\n",
    "# aggregated per weeks or days\n",
    "def daysPipeline(city,start_unix_time,end_unix_time):\n",
    "    return [\n",
    "    {\n",
    "        '$match': {\n",
    "            'city': city,\n",
    "            'init_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            },\n",
    "            'final_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'duration': {\n",
    "                '$divide': [\n",
    "                    { '$subtract': ['$final_time', '$init_time'] },\n",
    "                    60  # Divide by 60 to convert seconds to minutes\n",
    "                ]\n",
    "            },\n",
    "            'weekDay': {'$dayOfWeek': '$init_date'},\n",
    "        }\n",
    "    },{\n",
    "        '$sort': { #since the sorting is done in the pipeline, if the result is more than ram capacity then we will get an error. to fix this we can use external sorting with numpy\n",
    "            'duration': 1  # Sorting by duration in ascending order\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': {'week_day': '$weekDay'},\n",
    "            'durations': {'$push': '$duration'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "def weeksPipeline(city,start_unix_time,end_unix_time):\n",
    "    return [\n",
    "    {\n",
    "        '$match': {\n",
    "            'city': city,\n",
    "            'init_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            },\n",
    "            'final_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'duration': {\n",
    "                '$divide': [\n",
    "                    { '$subtract': ['$final_time', '$init_time'] },\n",
    "                    60  # Divide by 60 to convert seconds to minutes\n",
    "                ]\n",
    "            },\n",
    "            'week': {'$isoWeek': '$init_date'},\n",
    "        }\n",
    "    },{\n",
    "        '$sort': { #since the sorting is done in the pipeline, if the result is more than ram capacity then we will get an error. to fix this we can use external sorting with numpy\n",
    "            'duration': 1  # Sorting by duration in ascending order\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': {'week': '$week'},\n",
    "            'durations': {'$push': '$duration'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "def plotter(data,City, Company, type):\n",
    "    data.sort(key=lambda x:x[\"_id\"][type])\n",
    "    plt.figure()\n",
    "    for it in range(len(data)):\n",
    "        el=data[it]\n",
    "        lenDurations=len(el[\"durations\"])\n",
    "        cumulate=np.zeros(lenDurations)\n",
    "        for i in range (lenDurations):\n",
    "            cumulate[i] = (i+1)/len(cumulate)\n",
    "        plt.semilogx(el[\"durations\"], cumulate,label = 'Day : '+str(it+1))\n",
    "    # print(\"For the {} Day the average duration of bookings is:{}\".format(it+1,np.mean(el[\"durations\"])))\n",
    "    plt.legend()\n",
    "    plt.title('Cdf of bookings durations per Day in {}, enjoy, November 2017-January 2018'.format(City))\n",
    "    plt.xlabel('Duration [min]')\n",
    "    plt.ylabel('Percentage [%]')\n",
    "    plt.show()\n",
    "\n",
    "booking_days_data = enjoy_permenant_booking.aggregate(daysPipeline('Torino',start_unix_time,end_unix_time))\n",
    "plotter(list(booking_days_data),'Torino','Enjoy','week_day')\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#2.2\n",
    "#system utilization over time, aggregated per hour of the day\n",
    "from datetime import datetime, timedelta\n",
    "def oopsPipeline(city,start_unix_time,end_unix_time):\n",
    "    return [\n",
    "    {\n",
    "        '$match': {\n",
    "            'city': city,\n",
    "            'init_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            },\n",
    "            'final_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'duration': {\n",
    "                '$divide': [\n",
    "                    { '$subtract': ['$final_time', '$init_time'] },\n",
    "                    60  # Divide by 60 to convert seconds to minutes\n",
    "                ]\n",
    "            },\n",
    "            'day': {'$dayOfMonth': '$init_date'},\n",
    "            'hour': {'$hour': '$init_date'},\n",
    "            'date': {\n",
    "                '$dateToString': {\n",
    "                    'format': '%Y-%m-%d',\n",
    "                    'date': '$init_date'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group':{\n",
    "            '_id': {'day': '$day', 'hour': '$hour', 'date': '$date'},\n",
    "            'total_count': {'$sum': 1},\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$_id.date',\n",
    "            'hours': {\n",
    "                '$push': {\n",
    "                    'hour': '$_id.hour',\n",
    "                    'total_count': '$total_count'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1,\n",
    "            'hours.hour': 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "book_data = list(permenant_booking.aggregate(oopsPipeline('Stuttgart',start_unix_time,end_unix_time)))\n",
    "park_data = list(permenant_parking.aggregate(oopsPipeline('Stuttgart',start_unix_time,end_unix_time)))\n",
    "\n",
    "flattened_data = []\n",
    "for entry in book_data:\n",
    "    date = entry['_id']\n",
    "    for hour_data in entry['hours']:\n",
    "        flattened_data.append({\n",
    "            'date': date,\n",
    "            'hour': hour_data['hour'],\n",
    "            'total_count': hour_data['total_count']\n",
    "        })\n",
    "all_dates =[]\n",
    "all_values = []\n",
    "for entry in flattened_data:\n",
    "    current_date = datetime.strptime(entry['date'], '%Y-%m-%d')\n",
    "    all_dates.append(current_date+timedelta(hours=entry['hour']))\n",
    "    all_values.append(entry['total_count'])\n",
    "\n",
    "flattened_park_data = []\n",
    "for entry in park_data:\n",
    "    date = entry['_id']\n",
    "    for hour_data in entry['hours']:\n",
    "        flattened_park_data.append({\n",
    "            'date': date,\n",
    "            'hour': hour_data['hour'],\n",
    "            'total_count': hour_data['total_count']\n",
    "        })\n",
    "park_all_dates =[]\n",
    "park_all_values = []\n",
    "for entry in flattened_park_data:\n",
    "    current_date = datetime.strptime(entry['date'], '%Y-%m-%d')\n",
    "    park_all_dates.append(current_date+timedelta(hours=entry['hour']))\n",
    "    park_all_values.append(entry['total_count'])\n",
    "\n",
    "unique_dates = sorted(set(date.date() for date in all_dates))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(all_dates, all_values, label='Book', color='blue')\n",
    "plt.plot(park_all_dates, park_all_values, label='Park', color='orange')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Total Counts Across Dates and Hours')\n",
    "plt.grid(True)\n",
    "plt.xticks(unique_dates,rotation=90, fontsize=5)\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#2.3\n",
    "#drive a critical analysis of the data and filter the outlier\n",
    "from datetime import datetime, timedelta\n",
    "def booking_duration_filter_pipeline(city,start_unix_time,end_unix_time):\n",
    "    return [\n",
    "    {\n",
    "        '$match': {\n",
    "            'city': city,\n",
    "            'init_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            },\n",
    "            'final_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'duration': {\n",
    "                '$divide': [\n",
    "                    { '$subtract': ['$final_time', '$init_time'] },\n",
    "                    60  # Divide by 60 to convert seconds to minutes\n",
    "                ]\n",
    "            },\n",
    "            'day': {'$dayOfMonth': '$init_date'},\n",
    "            'hour': {'$hour': '$init_date'},\n",
    "            'date': {\n",
    "                '$dateToString': {\n",
    "                    'format': '%Y-%m-%d',\n",
    "                    'date': '$init_date'\n",
    "                }\n",
    "            },\n",
    "            'moved': {\n",
    "                '$ne':[\n",
    "                    {\"$arrayElemAt\": [ \"$origin_destination.coordinates\", 0]},\n",
    "                    {\"$arrayElemAt\": [ \"$origin_destination.coordinates\", 1]}\n",
    "                 ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$match': {\n",
    "            'moved': True,\n",
    "            'duration':{'$gt':5, '$lt':180},\n",
    "                \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group':{\n",
    "            '_id': {'day': '$day', 'hour': '$hour', 'date': '$date'},\n",
    "            'total_count': {'$sum': 1},\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$_id.date',\n",
    "            'hours': {\n",
    "                '$push': {\n",
    "                    'date': '$_id.date',\n",
    "                    'hour': '$_id.hour',\n",
    "                    'total_count': '$total_count'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1,\n",
    "            'hours.hour': 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def poarking_duration_filter_pipeline(city,start_unix_time,end_unix_time):\n",
    "    return [\n",
    "    {\n",
    "        '$match': {\n",
    "            'city': city,\n",
    "            'init_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            },\n",
    "            'final_time': {\n",
    "                '$gte': start_unix_time,\n",
    "                '$lte': end_unix_time\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            '_id': 0,\n",
    "            'duration': {\n",
    "                '$divide': [\n",
    "                    { '$subtract': ['$final_time', '$init_time'] },\n",
    "                    60  # Divide by 60 to convert seconds to minutes\n",
    "                ]\n",
    "            },\n",
    "            'day': {'$dayOfMonth': '$init_date'},\n",
    "            'hour': {'$hour': '$init_date'},\n",
    "            'date': {\n",
    "                '$dateToString': {\n",
    "                    'format': '%Y-%m-%d',\n",
    "                    'date': '$init_date'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$match': {\n",
    "            'duration':{'$gt':5, '$lt':720},\n",
    "                \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group':{\n",
    "            '_id': {'day': '$day', 'hour': '$hour', 'date': '$date'},\n",
    "            'total_count': {'$sum': 1},\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$_id.date',\n",
    "            'hours': {\n",
    "                '$push': {\n",
    "                    'date': '$_id.date',\n",
    "                    'hour': '$_id.hour',\n",
    "                    'total_count': '$total_count'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1,\n",
    "            'hours.hour': 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#2.4\n",
    "#aggregated by the hours of th days to get a better look on the population change over time of the day\n",
    "book_total = list(permenant_booking.aggregate(oopsPipeline22('Seattle',start_unix_time,end_unix_time)))\n",
    "park_total = list(permenant_parking.aggregate(oopsPipeline22('Seattle',start_unix_time,end_unix_time)))\n",
    "\n",
    "flattened_data = []\n",
    "for entry in book_total:\n",
    "    flattened_data.append(entry['total_per_hour'])\n",
    "\n",
    "flattened_park_data = []\n",
    "for entry in park_total:\n",
    "    flattened_park_data.append(entry['total_per_hour'])\n",
    "\n",
    "bar_width = 0.40\n",
    "x_positions = np.arange(24)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(x_positions - bar_width/2, flattened_data, bar_width, label='Book', color='skyblue')\n",
    "plt.bar(x_positions + bar_width/2, flattened_park_data, bar_width, label='Park', color='orange')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Count')\n",
    "plt.legend()\n",
    "plt.title('Total Counts Across Dates and Hours')\n",
    "plt.grid(True)\n",
    "plt.xticks(x_positions,range(0,24),rotation=60, fontsize=10)\n",
    "plt.show()\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#2.5\n",
    "#avg - median - std - percentiles 90\n",
    "def book_stat_pipeline(city, start_unix_time, end_unix_time):\n",
    "  return [\n",
    "      {\n",
    "        \"$match\":{\n",
    "        \"city\": city,\n",
    "          \"init_time\":{\"$gte\":start_unix_time,\"$lte\":end_unix_time},\n",
    "          \"final_time\":{\"$gte\":start_unix_time,\"$lte\":end_unix_time},\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"$project\":{\n",
    "        \"hour\": { \"$hour\": \"$init_date\" },\n",
    "        \"day\": { \"$dayOfMonth\": \"$init_date\" },\n",
    "        \"duration\":{\"$divide\" : [{\"$subtract\":[\"$final_time\",\"$init_time\"]},60]},\n",
    "        \"moved\": { \"$ne\": [\n",
    "            {\"$arrayElemAt\": [ \"$origin_destination.coordinates\", 0]},\n",
    "            {\"$arrayElemAt\": [ \"$origin_destination.coordinates\", 1]}\n",
    "            ]\n",
    "        }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"$match\":{\n",
    "          \"moved\":True,\n",
    "          \"duration\":{\"$lte\":180, \"$gte\":5}\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"$sort\":{\"duration\":1}\n",
    "      },\n",
    "      {\n",
    "        \"$group\":{\"_id\": {\"day\":\"$day\"},\"list_values\": { \"$push\": \"$duration\" }}\n",
    "      },\n",
    "      {\n",
    "        \"$project\":{\n",
    "          \"day\":1,\n",
    "          \"average\":{\"$avg\":\"$list_values\"},\n",
    "          \"percentile_90\":{\"$arrayElemAt\":[\"$list_values\",\n",
    "              {\"$floor\":{ \"$multiply\": [0.9,{\"$size\": \"$list_values\"}]}}]},\n",
    "          \"median\":{\"$arrayElemAt\":[\"$list_values\",\n",
    "              {\"$floor\":{ \"$multiply\": [0.5,{\"$size\": \"$list_values\"}]}}]},\n",
    "          \"st_Dev\":{\"$stdDevSamp\":\"$list_values\"}\n",
    "        }\n",
    "      },\n",
    " ]\n",
    "\n",
    "def park_stat_pipeline(city, start_unix_time, end_unix_time):\n",
    "  return [\n",
    "    {\n",
    "    \"$match\":{\n",
    "      \"city\": city,\n",
    "      \"init_time\":{\"$gte\":start_unix_time,\"$lte\":end_unix_time},\n",
    "      \"final_time\":{\"$gte\":start_unix_time,\"$lte\":end_unix_time},\n",
    "    }\n",
    "    },\n",
    "    {\n",
    "    \"$project\":{\n",
    "      \"hour\": { \"$hour\": \"$init_date\" },\n",
    "      \"day\": { \"$dayOfMonth\": \"$init_date\" },\n",
    "      \"duration\":{\"$divide\" : [{\"$subtract\":[\"$final_time\",\"$init_time\"]},60]}\n",
    "    }\n",
    "    },{\n",
    "        \"$match\":{\n",
    "          \"duration\":{\"$lt\":720, \"$gt\":5}\n",
    "        }\n",
    "      },\n",
    "    {\n",
    "    \"$sort\":{\"duration\":1}\n",
    "    },\n",
    "    {\n",
    "    \"$group\":{\"_id\": {\"day\":\"$day\"},\"list_values\": { \"$push\": \"$duration\" }}\n",
    "    },\n",
    "    {\n",
    "    \"$project\":{\n",
    "      \"day\":1,\n",
    "      \"average\":{\"$avg\":\"$list_values\"},\n",
    "      \"percentile_90\":{\n",
    "        \"$arrayElemAt\":[\n",
    "          \"$list_values\",\n",
    "                        {\"$floor\":{ \n",
    "                          \"$multiply\": \n",
    "                          [0.9,{\"$size\": \"$list_values\"}]\n",
    "                          }}]},\n",
    "                          \"median\":{\n",
    "                            \"$arrayElemAt\":[\n",
    "                              \"$list_values\",\n",
    "                              {\"$floor\":\n",
    "                                { \n",
    "                                 \"$multiply\": \n",
    "                                 [0.5,{\"$size\": \"$list_values\"}]\n",
    "                                 }\n",
    "                              }\n",
    "                            ]\n",
    "                          },\n",
    "                                 \"st_Dev\":{\"$stdDevSamp\":\"$list_values\"},\n",
    "      }\n",
    "    },\n",
    " ]\n",
    "\n",
    "Bookings_per_hours_date_filtered = list(enjoy_permenant_booking.aggregate(book_stat_pipeline('Torino',start_unix_time,end_unix_time)))\n",
    "\n",
    "Bookings_per_hours_date_filtered.sort(key=lambda x:(x[\"_id\"][\"day\"]))\n",
    "\n",
    "averages_filtered=[el[\"average\"] for el in Bookings_per_hours_date_filtered]\n",
    "percentile_90_filtered=[el[\"percentile_90\"] for el in Bookings_per_hours_date_filtered]\n",
    "median_filtered=[el[\"median\"] for el in Bookings_per_hours_date_filtered]\n",
    "st_Dev_duration_filtered=[el[\"st_Dev\"] for el in Bookings_per_hours_date_filtered]\n",
    "days=[str(el[\"_id\"][\"day\"]) for el in Bookings_per_hours_date_filtered]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(days,averages_filtered,label=\"Avg_fil\")\n",
    "plt.plot(days,percentile_90_filtered,label=\"Per_90_fil\")\n",
    "plt.plot(days,median_filtered,label=\"Med_fil\")\n",
    "plt.plot(days,st_Dev_duration_filtered,label=\"Std_dev_fil\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xticks(rotation=60)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Duration')\n",
    "plt.title('Statistics of duration bookings')\n",
    "plt.show()\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#2.6\n",
    "#location of the parked cars on the map\n",
    "start_unix_time = datetime(2017, 11, 1, 0, 0, 0).replace(tzinfo=timezone.utc).timestamp()\n",
    "end_unix_time = datetime(2018, 1, 31, 23, 59, 59).replace(tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "booking_locations = list(enjoy_permenant_booking.aggregate([\n",
    "    {'$match': {'city': 'Torino'}},\n",
    "    {'$project': {\n",
    "        '_id': 0,\n",
    "        'duration': {'$divide': [{'$subtract': ['$final_time', '$init_time']}, 60]},\n",
    "        'plate': 1,\n",
    "        'city': 1,\n",
    "        'init_time': 1,\n",
    "        'init_date': 1,\n",
    "        'year': {'$year': '$init_date'},\n",
    "        'month': {'$month': '$init_date'},\n",
    "        'day': {'$dayOfWeek': '$init_date'},\n",
    "        'hour': {'$hour': '$init_date'},\n",
    "        'origin_longitude': {'$arrayElemAt': [{'$arrayElemAt':['$origin_destination.coordinates',0]}, 1]},\n",
    "        'origin_latitude': {'$arrayElemAt': [{'$arrayElemAt':['$origin_destination.coordinates',0]}, 0]},\n",
    "        'dest_longitude': {'$arrayElemAt': [{'$arrayElemAt':['$origin_destination.coordinates',1]}, 1]},\n",
    "        'dest_latitude': {'$arrayElemAt': [{'$arrayElemAt':['$origin_destination.coordinates',1]}, 0]}\n",
    "    }},\n",
    "    {'$match': {\n",
    "        'duration': {'$gte': 5}, \n",
    "        'init_time': {'$gte': start_unix_time, '$lte': end_unix_time},\n",
    "        'hour': {'$gte': 8, '$lt': 10},\n",
    "        'day':{'$gte': 1, '$lte':5}\n",
    "    }}\n",
    "]))\n",
    "\n",
    "my_pd = pd.DataFrame(booking_locations)\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import folium\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "longitude = my_pd['dest_longitude'].iloc[:]\n",
    "latitude = my_pd['dest_latitude'].iloc[:]\n",
    "fina_df = my_pd[['dest_latitude','dest_longitude']]\n",
    "\n",
    "my_geometry = gpd.points_from_xy(latitude,longitude,crs='EPSG:4326')\n",
    "\n",
    "gdf = GeoDataFrame(fina_df, geometry=my_geometry)\n",
    "gdf.explore()\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#2.6.b\n",
    "#HeatMap of the parked cars\n",
    "# according to the documentation of pymongo and mongodb, $dayOfWeek returns 1 for Sunday, 2 for Monday, to 7 for Saturday\n",
    "# so we chose 1 and 7 to represent the weekend\n",
    "# and 2 to 6 to represent the weekdays\n",
    "#and this is the refrerence https://docs.mongodb.com/manual/reference/operator/aggregation/dayOfWeek/\n",
    "\n",
    "start_unix_time = datetime(2017, 11, 1, 0, 0, 0).replace(tzinfo=timezone.utc).timestamp()\n",
    "end_unix_time = datetime(2018, 1, 31, 23, 59, 59).replace(tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "booking_locations = list(permenant_booking.aggregate([\n",
    "    {'$match': {'city': 'Seattle'}},\n",
    "    {'$project': {\n",
    "        '_id': 0,\n",
    "        'duration': {'$divide': [{'$subtract': ['$final_time', '$init_time']}, 60]},\n",
    "        'plate': 1,\n",
    "        'city': 1,\n",
    "        'init_time': 1,\n",
    "        'init_date': 1,\n",
    "        'year': {'$year': '$init_date'},\n",
    "        'month': {'$month': '$init_date'},\n",
    "        'day': {'$dayOfWeek': '$init_date'},\n",
    "        'hour': {'$hour': '$init_date'},\n",
    "        'origin_longitude': {'$arrayElemAt': [{'$arrayElemAt':['$origin_destination.coordinates',0]}, 1]},\n",
    "        'origin_latitude': {'$arrayElemAt': [{'$arrayElemAt':['$origin_destination.coordinates',0]}, 0]},\n",
    "        'dest_longitude': {'$arrayElemAt': [{'$arrayElemAt':['$origin_destination.coordinates',1]}, 1]},\n",
    "        'dest_latitude': {'$arrayElemAt': [{'$arrayElemAt':['$origin_destination.coordinates',1]}, 0]}\n",
    "    }},\n",
    "    {'$match': {\n",
    "        'duration': {'$gte': 5}, \n",
    "        'init_time': {'$gte': start_unix_time, '$lte': end_unix_time},\n",
    "        # 'hour': {'$gte': 8, '$lt': 10},\n",
    "        # 'day':{'$gte': 1, '$lte':7}\n",
    "    }}\n",
    "]))\n",
    "\n",
    "\n",
    "my_pd = pd.DataFrame(booking_locations)\n",
    "weekday = my_pd[(my_pd['day'] == 1) | (my_pd['day'] == 7)]\n",
    "# weekday = my_pd[(my_pd['day'] > 1) & (my_pd['day'] < 7)]\n",
    "weekday_morning = weekday[(weekday['hour'] >= 8) & (weekday['hour'] <= 10)]\n",
    "longitude = weekday_morning['dest_longitude'].iloc[:]\n",
    "latitude = weekday_morning['dest_latitude'].iloc[:]\n",
    "fina_df = weekday_morning[['dest_latitude','dest_longitude']]\n",
    "fin_final_df = fina_df.values.tolist()\n",
    "\n",
    "parking = np.zeros((len(fin_final_df),2))\n",
    "for i in range (len(fin_final_df)):\n",
    "    parking[i,1] = resultado[i][0]\n",
    "    parking[i,0] = resultado[i][1]\n",
    "    \n",
    "parking_coordinates = pd.DataFrame(parking)\n",
    "parking_coordinates.rename(columns={0:\"latitude\", 1:\"longitude\"}, inplace=True)\n",
    "parking_coordinates.to_csv (r'/Users/graybook/Downloads/Italy_shapefile/parkinggg.csv', index = False, header=True)\n",
    "\n",
    "df = pd.read_csv(r'/Users/graybook/Downloads/Italy_shapefile/parkinggg.csv') \n",
    "geometry1 = [Point(xy) for xy in zip(df[\"longitude\"], df[\"latitude\"])]  \n",
    "\n",
    "geo_df1 = gpd.GeoDataFrame(df, geometry=geometry1)\n",
    "\n",
    "mymap = gpd.read_file(r'/Users/graybook/Downloads/Neighborhood_Map_Atlas_Neighborhoods/Neighborhood_Map_Atlas_Neighborhoods.shp')\n",
    "mymap.to_crs(epsg = 4326 , inplace = True)\n",
    "c=0\n",
    "counter=[]\n",
    "for i in mymap['geometry']:\n",
    "    for j in geo_df1['geometry']:\n",
    "        if i.contains(j):\n",
    "            c+=1\n",
    "    counter.append(c)\n",
    "    c=0\n",
    "mymap['counter']=counter\n",
    "\n",
    "mymap.plot(column = 'counter',cmap='coolwarm',legend = True,figsize=(10,10))\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Seattle Density HeatMap')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
